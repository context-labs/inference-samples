{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5942b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/michaelryaboy/recent-projects/inference-webhook/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q openai wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe373c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢¬†Cell¬†2 ‚Äì imports & client\n",
    "import os, re, asyncio\n",
    "from typing import List, Literal\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.inference.net/v1\",          # inference.net endpoint\n",
    "    api_key=os.getenv(\"INFERENCE_API_KEY\"),\n",
    ")\n",
    "MODEL = \"mistralai/mistral-nemo-12b-instruct/fp-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1790272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Filtered list ‚Üí 52002\n",
      "first 10 domains ‚Üí ['ababanews.net', 'ababeelrealtors.com', 'abacombs.com', 'abacotoner.com', 'abadcult.org', 'abannebebek.com', 'abanoteolo.it', 'abarcart.com', 'abarrotesbombin.click', 'abaseballtime.com']\n"
     ]
    }
   ],
   "source": [
    "# fetch domains from https://gist.githubusercontent.com/mrmps/fbf29299d4b4401e6cfd659fd637fe41/raw/10920268c7a806778b954568f88a1734ea59ca8a/gistfile1.txt\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"https://gist.githubusercontent.com/mrmps/fbf29299d4b4401e6cfd659fd637fe41/raw/10920268c7a806778b954568f88a1734ea59ca8a/gistfile1.txt\")\n",
    "\n",
    "raw_domains = response.text.split(\"\\n\")\n",
    "\n",
    "import re\n",
    "from wordfreq import zipf_frequency   # pip install wordfreq\n",
    "\n",
    "VOWELS = set(\"aeiou\")\n",
    "\n",
    "def looks_good(domain: str) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristically decide whether `domain` is worth a closer look.\n",
    "\n",
    "    ‚Ä¢ Accepts **any** TLD (only rejects punycode or multi‚Äëdot domains)\n",
    "    ‚Ä¢ ASCII letters only in the SLD  (no digits, hyphens, punycode)\n",
    "    ‚Ä¢ 4‚Äì16 chars, at least one vowel *and* one consonant\n",
    "    ‚Ä¢ Balanced vowel ratio: 0.2¬†‚Äì¬†0.8\n",
    "    ‚Ä¢ No 4‚Äëchar runs of vowels or consonants, no triple repeats,\n",
    "      no doubled first letter (‚Äúaafoo‚Äù), no placeholder words\n",
    "    ‚Ä¢ Must look *somewhat* like an English word (Zipf ‚â•‚ÄØ1.2) **or**\n",
    "      contain an English sub‚Äëchunk ‚â•‚ÄØ4 letters with Zipf ‚â•‚ÄØ3.0\n",
    "    \"\"\"\n",
    "\n",
    "    domain = domain.strip().lower()\n",
    "\n",
    "    # structural sanity -------------------------------------------------\n",
    "    if domain.startswith(\"xn--\") or domain.count(\".\") != 1:\n",
    "        return False\n",
    "\n",
    "    sld, _, tld = domain.partition(\".\")   # we accept every tld now\n",
    "    if not 4 <= len(sld) <= 16:\n",
    "        return False\n",
    "    if not re.fullmatch(r\"[a-z]+\", sld):\n",
    "        return False                        # digits / hyphens ‚Üí out\n",
    "\n",
    "    # quick character‚Äëpattern checks -----------------------------------\n",
    "    if sld[0] == sld[1]:                   # reject ‚Äúaafoo‚Äù, ‚Äúbbtech‚Äù\n",
    "        return False\n",
    "    if re.search(r\"(.)\\1\\1\", sld):         # any triple repeat\n",
    "        return False\n",
    "    if re.search(r\"[aeiou]{4,}\", sld) or re.search(r\"[bcdfghjklmnpqrstvwxyz]{4,}\", sld):\n",
    "        return False\n",
    "    if re.fullmatch(r\"(?:[bcdfghjklmnpqrstvwxyz][aeiou]){4,}\", sld):\n",
    "        return False                       # gubarecoti‚Äëstyle generator junk\n",
    "\n",
    "    # vowel / consonant balance ----------------------------------------\n",
    "    v = sum(c in VOWELS for c in sld)\n",
    "    if v == 0 or v == len(sld):\n",
    "        return False\n",
    "    ratio = v / len(sld)\n",
    "    if not (0.20 <= ratio <= 0.80):\n",
    "        return False\n",
    "\n",
    "    # ‚Äúlooks like a word‚Äù signal ---------------------------------------\n",
    "    freq = zipf_frequency(sld, \"en\")\n",
    "    if freq >= 1.2:\n",
    "        return True                        # good enough\n",
    "\n",
    "    # fallback: does it *contain* a real 4‚Äëletter chunk?\n",
    "    for i in range(len(sld) - 3):\n",
    "        chunk = sld[i:i+4]\n",
    "        if zipf_frequency(chunk, \"en\") >= 3.0:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "domains = [d for d in raw_domains if looks_good(d)]\n",
    "print(\"Len Filtered list ‚Üí\", len(domains))\n",
    "print(\"first 10 domains ‚Üí\", domains[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "\n",
    "\n",
    "# üü¢¬†Cell¬†3 ‚Äì Pydantic schema (reasoning BEFORE score)\n",
    "class DomainValuation(BaseModel):\n",
    "    reasoning: str\n",
    "    score:  str\n",
    "\n",
    "    model_config = ConfigDict(extra='forbid')   \n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a senior domain‚Äëname appraiser with 15‚ÄØyears of aftermarket sales data.\n",
    "First think through the valuation factors, then output JSON **in this exact order**:\n",
    "reasoning ‚Üí score.  Follow the schema.\n",
    "\n",
    "Evaluation rubric¬†(consider ALL factors¬†‚Äì absence of any single factor prevents a perfect score):\n",
    "\n",
    "1¬†‚Ä¢¬†Extension quality¬†‚Äì .com > .net ‚âà .org¬†‚âª others  \n",
    "2¬†‚Ä¢¬†Length¬†‚Äì ideal ‚â§‚ÄØ8 characters, shorter is better  \n",
    "3¬†‚Ä¢¬†Word count¬†‚Äì single meaningful word > two‚Äëword phrase; no fragments  \n",
    "4¬†‚Ä¢¬†Pronounceability¬†‚Äì passes ‚Äúradio¬†test‚Äù (clear spelling upon hearing)  \n",
    "5¬†‚Ä¢¬†Memorability & brandability¬†‚Äì evokes imagery or category, no hyphens/numbers  \n",
    "6¬†‚Ä¢¬†Search demand¬†‚Äì high monthly exact‚Äëmatch keyword volume is a plus  \n",
    "7¬†‚Ä¢¬†Commercial intent¬†‚Äì aligns with lucrative verticals (finance, AI, health, etc.)  \n",
    "8¬†‚Ä¢¬†Trademarks¬†‚Äì zero obvious TM conflicts; risky names are penalised  \n",
    "9¬†‚Ä¢¬†Comparable sales¬†‚Äì recent public comps of similar length/keywords/TLD  \n",
    "10¬†‚Ä¢¬†Market trends¬†‚Äì includes rising buzzwords or technologies without being ephemeral  \n",
    "\n",
    "Scoring guide:\n",
    "\n",
    "¬†¬†90‚Äë100¬†¬†excellent ‚Äì premium asset, likely ‚â•‚ÄØ$50‚ÄØk  \n",
    "¬†¬†70‚Äë89¬†¬†¬†good ‚Äì solid brand, low‚Äëfive‚Äëfigure potential  \n",
    "¬†¬†40‚Äë69¬†¬†¬†average ‚Äì resale value a few hundred‚Äëfew thousand USD  \n",
    "¬†¬†¬†1‚Äë39¬†¬†¬†poor ‚Äì little intrinsic value  \n",
    "\n",
    "‚Äòreasoning‚Äô¬†= a concise chain of thought thinking through the factors and scoring the domain.  \n",
    "If unsure, round the score DOWN.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9435a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'domain_valuation', 'strict': True, 'schema': {'additionalProperties': False, 'properties': {'reasoning': {'title': 'Reasoning', 'type': 'string'}, 'score': {'title': 'Score', 'type': 'string'}}, 'required': ['reasoning', 'score'], 'title': 'DomainValuation', 'type': 'object'}}\n"
     ]
    }
   ],
   "source": [
    "DOMAIN_SCHEMA = {\n",
    "    \"name\":   \"domain_valuation\",\n",
    "    \"strict\": True,\n",
    "    \"schema\": DomainValuation.model_json_schema()      # auto‚Äëgenerated üéâ\n",
    "}\n",
    "\n",
    "print(DOMAIN_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42f94f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line(domain: str, custom_id: str):\n",
    "    body = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\",   \"content\": f\"Domain: {domain}\"}\n",
    "        ],\n",
    "        \"response_format\": {           # structured outputs!\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": DOMAIN_SCHEMA\n",
    "        },\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 1200\n",
    "    }\n",
    "    return {\n",
    "        \"custom_id\": custom_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": body\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f15398a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='WRfogb6iueXZe07AILloi', bytes=None, created_at=1753835433893, filename=None, object=None, purpose=None, status=None, expires_at=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "MAX_LINES = 1\n",
    "items = domains[:MAX_LINES]  # use your actual list variable\n",
    "\n",
    "# Write the file, one request per line using make_line\n",
    "with open(\"batchinput.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, dom in enumerate(items):\n",
    "        line = make_line(dom.strip(), custom_id=str(i))\n",
    "        f.write(f\"{json.dumps(line)}\\n\")\n",
    "\n",
    "# Upload the file using openai.files.create\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(\"batchinput.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f083a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRfogb6iueXZe07AILloi\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'error': 'Failed to retrieve batch'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_input_file\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m----> 2\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_input_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "File \u001b[0;32m~/recent-projects/inference-webhook/venv/lib/python3.9/site-packages/openai/resources/batches.py:138\u001b[0m, in \u001b[0;36mBatches.retrieve\u001b[0;34m(self, batch_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch_id:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `batch_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/batches/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recent-projects/inference-webhook/venv/lib/python3.9/site-packages/openai/_base_client.py:1188\u001b[0m, in \u001b[0;36mSyncAPIClient.get\u001b[0;34m(self, path, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1185\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# it understands the type variables\u001b[39;00m\n\u001b[0;32m-> 1188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/recent-projects/inference-webhook/venv/lib/python3.9/site-packages/openai/_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 500 - {'error': 'Failed to retrieve batch'}"
     ]
    }
   ],
   "source": [
    "print(batch_input_file.id)\n",
    "batch = client.batches.retrieve(batch_input_file.id)\n",
    "print(batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
