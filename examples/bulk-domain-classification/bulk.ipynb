{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e5942b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69743.25s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/michaelryaboy/recent-projects/inference-webhook/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q openai wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe373c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸŸ¢Â CellÂ 2 â€“ imports & client\n",
    "import os, re, asyncio\n",
    "from typing import List, Literal\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.inference.net/v1\",          # inference.net endpoint\n",
    "    api_key=os.getenv(\"INFERENCE_API_KEY\"),\n",
    ")\n",
    "MODEL = \"mistralai/mistral-nemo-12b-instruct/fp-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1790272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Filtered list â†’ 52002\n",
      "first 10 domains â†’ ['ababanews.net', 'ababeelrealtors.com', 'abacombs.com', 'abacotoner.com', 'abadcult.org', 'abannebebek.com', 'abanoteolo.it', 'abarcart.com', 'abarrotesbombin.click', 'abaseballtime.com']\n"
     ]
    }
   ],
   "source": [
    "# fetch domains from https://gist.githubusercontent.com/mrmps/fbf29299d4b4401e6cfd659fd637fe41/raw/10920268c7a806778b954568f88a1734ea59ca8a/gistfile1.txt\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"https://gist.githubusercontent.com/mrmps/fbf29299d4b4401e6cfd659fd637fe41/raw/10920268c7a806778b954568f88a1734ea59ca8a/gistfile1.txt\")\n",
    "\n",
    "raw_domains = response.text.split(\"\\n\")\n",
    "\n",
    "import re\n",
    "from wordfreq import zipf_frequency   # pip install wordfreq\n",
    "\n",
    "VOWELS = set(\"aeiou\")\n",
    "\n",
    "def looks_good(domain: str) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristically decide whether `domain` is worth a closer look.\n",
    "\n",
    "    â€¢ Accepts **any** TLD (only rejects punycode or multiâ€‘dot domains)\n",
    "    â€¢ ASCII letters only in the SLD  (no digits, hyphens, punycode)\n",
    "    â€¢ 4â€“16 chars, at least one vowel *and* one consonant\n",
    "    â€¢ Balanced vowel ratio: 0.2Â â€“Â 0.8\n",
    "    â€¢ No 4â€‘char runs of vowels or consonants, no triple repeats,\n",
    "      no doubled first letter (â€œaafooâ€), no placeholder words\n",
    "    â€¢ Must look *somewhat* like an English word (Zipf â‰¥â€¯1.2) **or**\n",
    "      contain an English subâ€‘chunk â‰¥â€¯4 letters with Zipf â‰¥â€¯3.0\n",
    "    \"\"\"\n",
    "\n",
    "    domain = domain.strip().lower()\n",
    "\n",
    "    # structural sanity -------------------------------------------------\n",
    "    if domain.startswith(\"xn--\") or domain.count(\".\") != 1:\n",
    "        return False\n",
    "\n",
    "    sld, _, tld = domain.partition(\".\")   # we accept every tld now\n",
    "    if not 4 <= len(sld) <= 16:\n",
    "        return False\n",
    "    if not re.fullmatch(r\"[a-z]+\", sld):\n",
    "        return False                        # digits / hyphens â†’ out\n",
    "\n",
    "    # quick characterâ€‘pattern checks -----------------------------------\n",
    "    if sld[0] == sld[1]:                   # reject â€œaafooâ€, â€œbbtechâ€\n",
    "        return False\n",
    "    if re.search(r\"(.)\\1\\1\", sld):         # any triple repeat\n",
    "        return False\n",
    "    if re.search(r\"[aeiou]{4,}\", sld) or re.search(r\"[bcdfghjklmnpqrstvwxyz]{4,}\", sld):\n",
    "        return False\n",
    "    if re.fullmatch(r\"(?:[bcdfghjklmnpqrstvwxyz][aeiou]){4,}\", sld):\n",
    "        return False                       # gubarecotiâ€‘style generator junk\n",
    "\n",
    "    # vowel / consonant balance ----------------------------------------\n",
    "    v = sum(c in VOWELS for c in sld)\n",
    "    if v == 0 or v == len(sld):\n",
    "        return False\n",
    "    ratio = v / len(sld)\n",
    "    if not (0.20 <= ratio <= 0.80):\n",
    "        return False\n",
    "\n",
    "    # â€œlooks like a wordâ€ signal ---------------------------------------\n",
    "    freq = zipf_frequency(sld, \"en\")\n",
    "    if freq >= 1.2:\n",
    "        return True                        # good enough\n",
    "\n",
    "    # fallback: does it *contain* a real 4â€‘letter chunk?\n",
    "    for i in range(len(sld) - 3):\n",
    "        chunk = sld[i:i+4]\n",
    "        if zipf_frequency(chunk, \"en\") >= 3.0:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "domains = [d for d in raw_domains if looks_good(d)]\n",
    "print(\"Len Filtered list â†’\", len(domains))\n",
    "print(\"first 10 domains â†’\", domains[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "\n",
    "\n",
    "# ğŸŸ¢Â CellÂ 3 â€“ Pydantic schema (reasoning BEFORE score)\n",
    "class DomainValuation(BaseModel):\n",
    "    reasoning: str\n",
    "    score:  str\n",
    "\n",
    "    model_config = ConfigDict(extra='forbid')   \n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a senior domainâ€‘name appraiser with 15â€¯years of aftermarket sales data.\n",
    "First think through the valuation factors, then output JSON **in this exact order**:\n",
    "reasoning â†’ score.  Follow the schema.\n",
    "\n",
    "Evaluation rubricÂ (consider ALL factorsÂ â€“ absence of any single factor prevents a perfect score):\n",
    "\n",
    "1Â â€¢Â Extension qualityÂ â€“ .com > .net â‰ˆ .orgÂ â‰» others  \n",
    "2Â â€¢Â LengthÂ â€“ ideal â‰¤â€¯8 characters, shorter is better  \n",
    "3Â â€¢Â Word countÂ â€“ single meaningful word > twoâ€‘word phrase; no fragments  \n",
    "4Â â€¢Â PronounceabilityÂ â€“ passes â€œradioÂ testâ€ (clear spelling upon hearing)  \n",
    "5Â â€¢Â Memorability & brandabilityÂ â€“ evokes imagery or category, no hyphens/numbers  \n",
    "6Â â€¢Â Search demandÂ â€“ high monthly exactâ€‘match keyword volume is a plus  \n",
    "7Â â€¢Â Commercial intentÂ â€“ aligns with lucrative verticals (finance, AI, health, etc.)  \n",
    "8Â â€¢Â TrademarksÂ â€“ zero obvious TM conflicts; risky names are penalised  \n",
    "9Â â€¢Â Comparable salesÂ â€“ recent public comps of similar length/keywords/TLD  \n",
    "10Â â€¢Â Market trendsÂ â€“ includes rising buzzwords or technologies without being ephemeral .ArithmeticError\n",
    "\n",
    "You don't have access to the internet, so do your best.\n",
    "\n",
    "Scoring guide:\n",
    "\n",
    "Â Â 90â€‘100Â Â excellent â€“ premium asset, likely â‰¥â€¯$50â€¯k  \n",
    "Â Â 70â€‘89Â Â Â good â€“ solid brand, lowâ€‘fiveâ€‘figure potential  \n",
    "Â Â 40â€‘69Â Â Â average â€“ resale value a few hundredâ€‘few thousand USD  \n",
    "Â Â Â 1â€‘39Â Â Â poor â€“ little intrinsic value  \n",
    "\n",
    "â€˜reasoningâ€™Â = a concise chain of thought thinking through the factors and scoring the domain.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9435a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'domain_valuation', 'strict': True, 'schema': {'additionalProperties': False, 'properties': {'reasoning': {'title': 'Reasoning', 'type': 'string'}, 'score': {'title': 'Score', 'type': 'string'}}, 'required': ['reasoning', 'score'], 'title': 'DomainValuation', 'type': 'object'}}\n"
     ]
    }
   ],
   "source": [
    "DOMAIN_SCHEMA = {\n",
    "    \"name\":   \"domain_valuation\",\n",
    "    \"strict\": True,\n",
    "    \"schema\": DomainValuation.model_json_schema()      # autoâ€‘generated ğŸ‰\n",
    "}\n",
    "\n",
    "print(DOMAIN_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "42f94f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line(domain: str, custom_id: str):\n",
    "    body = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\",   \"content\": f\"Domain: {domain}\"}\n",
    "        ],\n",
    "        \"response_format\": {           # structured outputs!\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": DOMAIN_SCHEMA\n",
    "        },\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 1200\n",
    "    }\n",
    "    return {\n",
    "        \"custom_id\": custom_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": body\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f15398a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='uY0WAYNdE2a2_qPw7Kxqc', bytes=None, created_at=1753904467825, filename=None, object=None, purpose=None, status=None, expires_at=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "MAX_LINES = 1\n",
    "items = domains[:MAX_LINES]  # use your actual list variable\n",
    "\n",
    "# Write the file, one request per line using make_line\n",
    "with open(\"batchinput.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, dom in enumerate(items):\n",
    "        line = make_line(dom.strip(), custom_id=str(i))\n",
    "        f.write(f\"{json.dumps(line)}\\n\")\n",
    "\n",
    "# Upload the file using openai.files.create\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(\"batchinput.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d005130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='NBCI-G2-5CeUuexfJ_Hfb', completion_window='24h', created_at=1753904469972, endpoint='/v1/chat/completions', input_file_id='uY0WAYNdE2a2_qPw7Kxqc', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1753990869971, failed_at=None, finalizing_at=None, in_progress_at=1753904469971, metadata={'description': 'domain classification'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=1))\n"
     ]
    }
   ],
   "source": [
    "batch = client.batches.create(\n",
    "    input_file_id=batch_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    # Optional.\n",
    "    metadata={\n",
    "        \"description\": \"domain classification\"\n",
    "    },\n",
    ")\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "71d54372",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a non-empty value for `file_id` but received None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (state \u001b[38;5;241m:=\u001b[39m client\u001b[38;5;241m.\u001b[39mbatches\u001b[38;5;241m.\u001b[39mretrieve(batch\u001b[38;5;241m.\u001b[39mid)\u001b[38;5;241m.\u001b[39mstatus) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     12\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m file_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_file_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/recent-projects/inference-webhook/venv/lib/python3.9/site-packages/openai/resources/files.py:279\u001b[0m, in \u001b[0;36mFiles.content\u001b[0;34m(self, file_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03mReturns the contents of the specified file.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_id:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `file_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/binary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/content\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    283\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39m_legacy_response\u001b[38;5;241m.\u001b[39mHttpxBinaryResponseContent,\n\u001b[1;32m    287\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a non-empty value for `file_id` but received None"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Joyâ€‘sparking, noâ€‘try/except helper that turns a completed Inference.net\n",
    "batch into a tidy DataFrame with just three columns:\n",
    "\n",
    "    word Â· reasoning Â· score\n",
    "\"\"\"\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# â”€â”€ 1.  wait for the batch to finish â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "while (state := client.batches.retrieve(batch.id).status) == \"in_progress\":\n",
    "    time.sleep(1)\n",
    "\n",
    "file_response = client.files.content(batch.output_file_id)\n",
    "\n",
    "print(file_response.text)\n",
    "\n",
    "df = pd.DataFrame(columns=[\"reasoning\", \"score\"])\n",
    "# for every line, get reasoning and score\n",
    "for line in file_response.text.splitlines():\n",
    "    line_obj = json.loads(line)\n",
    "    # The response structure is: {\"response\": {\"body\": {\"choices\": [{\"message\": {\"content\": ...}}]}}}\n",
    "    # The \"reasoning\" and \"score\" are inside the message[\"content\"] as a JSON string.\n",
    "    # We'll parse that out and append to the DataFrame.\n",
    "    message_content = (\n",
    "        line_obj[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    )\n",
    "\n",
    "    print(message_content)\n",
    "    # Parse the content as JSON (it may be a string with newlines)\n",
    "    content_json = json.loads(message_content)\n",
    "    reasoning = content_json.get(\"reasoning\", \"\")\n",
    "    score = content_json.get(\"score\", \"\")\n",
    "    df.loc[len(df)] = [reasoning, score]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a474c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec3477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
