{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Sentiment with Structured Outputs and Inference.net\n",
    "\n",
    "This notebook demonstrates how to perform sentiment analysis on text data using the Structured Outputs capability of the OpenAI API, specifically leveraging the `meta-llama/llama-3.2-3b-instruct/fp-16` model via the Inference.net platform.\n",
    "\n",
    "By utilizing JSON Schema within the `response_format` parameter, we ensure that the model's output strictly adheres to a predefined structure, making it reliable for downstream processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, let's install the necessary library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import the required libraries and set up the OpenAI client to point to the Inference.net API endpoint using the `baseurl` parameter. Make sure you have your `INFERENCE_API_KEY` set in your environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# ‚Äî‚Äî Configuration ‚Äî‚Äî\n",
    "INFERENCE_API_KEY = os.getenv(\"INFERENCE_API_KEY\")\n",
    "\n",
    "# Inference.net client\n",
    "openai = OpenAI(\n",
    "    base_url=\"https://api.inference.net/v1\",\n",
    "    api_key=INFERENCE_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a list of example tweets that we will analyze for sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    # Ellen DeGeneres‚Äôs Oscar selfie (March¬†2,¬†2014)\n",
    "    \"If only Bradley's arm was longer. Best photo ever. #oscars\",\n",
    "    # Barack Obama‚Äôs re‚Äëelection celebration (Nov¬†6,¬†2012)\n",
    "    \"Four more years. #Obama2012\",\n",
    "    # Donald Trump‚Äôs infamous typo (May¬†31,¬†2017)\n",
    "    \"Despite the constant negative press covfefe\",\n",
    "    # Elon Musk on taking Tesla private (Aug¬†7,¬†2018)\n",
    "    \"Am considering taking Tesla private at $420. Funding secured.\",\n",
    "    # Barack Obama on the Orlando tragedy (June¬†12,¬†2016)\n",
    "    \"Shocked and saddened by the news from Orlando. Our hearts go out to all those impacted and we‚Äôll be there to help.\",\n",
    "    # Ariana¬†Grande after Manchester (May¬†22,¬†2017)\n",
    "    \"My heart is broken. From the bottom of my heart, I am so sorry. I don‚Äôt have the words.\",\n",
    "    # NASA on Curiosity landing (Aug¬†5,¬†2012)\n",
    "    \"Curiosity has landed on Mars! üéâüî¥ #MSL\"\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the JSON schema that the sentiment analysis output must follow. This schema requires the output to be a JSON object with two properties: `text` (the original tweet) and `sentiment` (an enum restricted to \"positive\", \"neutral\", or \"negative\"). The `strict: True` parameter ensures strict adherence to this schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_schema = {\n",
    "    \"name\": \"tweet_sentiment\",\n",
    "    \"strict\": True,\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"text\":      {\"type\": \"string\"},\n",
    "            \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"neutral\", \"negative\"]},\n",
    "        },\n",
    "        \"required\": [\"text\", \"sentiment\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a tweet as input and uses the Chat Completions API with the JSON schema above to analyze the sentiment. The `response_format` parameter, combined with `strict: True` in the schema, guarantees the output will be a valid JSON object conforming to the `sentiment_schema`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(tweet):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant. Respond in JSON format adhering to the given schema.\"},\n",
    "        {\"role\": \"user\", \"content\": tweet}\n",
    "    ]\n",
    "\n",
    "    resp = openai.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3.2-3b-instruct/fp-16\",\n",
    "        messages=messages,\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": sentiment_schema\n",
    "        }\n",
    "    )\n",
    "    return json.loads(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we iterate through our list of tweets and analyze the sentiment of each one using the `analyze_sentiment` function and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Just spilled coffee on my laptop right before a big meeting. Mondays, am I right? üò©‚òïÔ∏èüíª', 'sentiment': 'negative'}\n",
      "{'text': \"Can't believe @Raptors pulled off that comeback in OT! What a game üî•üèÄ #WeTheNorth\", 'sentiment': 'positive'}\n",
      "{'text': 'Is it just me, or does no one understand the importance of personal space on the subway?', 'sentiment': 'negative'}\n",
      "{'text': 'Your kitten is using the litter box consistently, which is a significant accomplishment.', 'sentiment': 'positive'}\n",
      "{'text': 'Listening to @BillieEilish‚Äôs latest album on repeat. Absolute masterpiece. ', 'sentiment': 'positive'}\n",
      "{'text': 'Waiting 2 hours for my food delivery and they forgot the fries. Literally starving over here. ', 'sentiment': 'negative'}\n",
      "{'text': 'feeling anxious but motivated to do my part', 'sentiment': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    print(analyze_sentiment(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! We just analyzed a bunch of tweets. Scaling this to millions or billions of examples can get challening with a workflow like this. To solve that, check out our webhook and batch apis:\n",
    "# [Webhooks](https://docs.inference.net/features/asynchronous-inference/webhooks/getting-started-with-webhooks)\n",
    "# [Batch API](https://docs.inference.net/features/batch-api)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
