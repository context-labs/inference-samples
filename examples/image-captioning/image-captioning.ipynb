{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Image Captioning at Scale with Vision LLMs.\n",
    "\n",
    "Vision models excel at understanding and describing images. They can grok the contents of images similar to how a human can, and can find patterns, objects, and even process many images at a time.\n",
    "\n",
    "In this notebook we'll learn how to caption images, and also extract insights from a large number of images.\n",
    "\n",
    "We'll be using a VLMs (Vision Language Model) to create a dataset of ugly and beautiful websites. For simplicity our dataset will only consist of a couple hundred images, but an AI lab seeking to improve LLM design ability may scale it to millions or billions of web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setting Up Your Captioning Pipeline\n",
    "\n",
    "First we download some libraries. We interact with Inference's API through OpenAI's official API client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai requests pillow datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can connect to Inference using the OpenAI SDK.\n",
    "\n",
    "We pass the Inference.net API baseurl, and make sure we have our API key set as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "import json\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "from io import BytesIO\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://batch.inference.net/v1\",\n",
    "    api_key=os.getenv(\"INFERENCE_API_KEY\"),\n",
    ")\n",
    "\n",
    "VISION_MODEL = \"google/gemma-3-27b-instruct/bf-16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll load the training split of the website screenshots dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 screenshots\n"
     ]
    }
   ],
   "source": [
    "N = 200\n",
    "ds = load_dataset(\n",
    "    \"Zexanima/website_screenshots_image_dataset\",\n",
    "    split=\"train\",                                   # âš ï¸ use â€œtestâ€ later for eval\n",
    "    streaming=False                                  # stream=True â‰ˆ zeroâ€‘RAM, slower\n",
    ").select(range(N))\n",
    "print(\"Loaded\", len(ds), \"screenshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a helper function to turn images into a data-URI so that we can pass them to our VLM API endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_data_uri(sample):\n",
    "    if isinstance(sample, Image.Image):\n",
    "        img = sample.convert(\"RGB\")\n",
    "        buf = BytesIO()\n",
    "        img.save(buf, format=\"PNG\", optimize=True)\n",
    "        data = buf.getvalue()\n",
    "    else:                                             # remote URL\n",
    "        data = requests.get(sample).content\n",
    "    b64 = base64.b64encode(data).decode(\"utf-8\")\n",
    "    return f\"data:image/png;base64,{b64}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Your First Image Captioning Request\n",
    "\n",
    "Let's start by captioning a few sample images. We'll download some images and convert them to base64 data URIs so our LLM API can process them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "SYSTEM_PROMPT = textwrap.dedent(\"\"\"\n",
    "    You are a senior productâ€‘designer assistant evaluating fullâ€‘page website\n",
    "    screenshots.  Perform **two independent judgements**:\n",
    "\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    1. landing_page (boolean)\n",
    "       â–¸Â TRUE Â â€“ the screenshot looks like the FIRST page a visitor sees\n",
    "                 (hero section or marquee visual, primary navigation bar,\n",
    "                 clear topâ€‘level callâ€‘toâ€‘action, little or no scroll offset).\n",
    "       â–¸Â FALSE â€“ any interior page, modal, or state that presumes prior\n",
    "                 navigation (pricing tables, blog posts, dashboards, etc.).\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    2. aesthetic  (integer 1â€‘5)\n",
    "       Rate overall visual polish **at the moment the screenshot was taken**.\n",
    "       Use the rubric below; intermediate numbers are **not permitted**.\n",
    "\n",
    "         1Â â–ªï¸Â PoorÂ Â Â â€“ chaotic layout, clashing colours, unreadable text,\n",
    "                      obvious placeholder or broken assets.\n",
    "         2Â â–ªï¸Â BelowÂ Avg â€“ dated styling, inconsistent spacing/alignment,\n",
    "                      lowâ€‘contrast elements, generic stock imagery.\n",
    "         3Â â–ªï¸Â AverageÂ  â€“ competent but ordinary; standard template vibes,\n",
    "                      minor visual debts allowed, no major UX antiâ€‘patterns.\n",
    "         4Â â–ªï¸Â GoodÂ Â Â Â â€“ clean hierarchy, harmonious palette & typography,\n",
    "                      responsiveâ€‘looking grid, purposeful imagery/icons.\n",
    "         5Â â–ªï¸Â Excellent â€“ editorialâ€‘grade art direction, meticulous spacing,\n",
    "                      delightful microâ€‘details, persuasive visual storytelling.\n",
    "\n",
    "       âœ±Â Ignore personal taste; judge by professional UI/UX heuristics\n",
    "         (legibility, balance, affordance, consistency, brand presence).\n",
    "\n",
    "    OUTPUT FORMAT  (strict)\n",
    "    ------------------------\n",
    "    {\n",
    "      \"landing_page\": <true|false>,\n",
    "      \"aesthetic\":    <integer 1â€‘5>\n",
    "    }\n",
    "\n",
    "    â€¢Â Return **JSON ONLY** â€“ no comments, no extra keys, no trailing commas.\n",
    "    â€¢Â If unsure, choose the **more conservative** (lower) aesthetic score.\n",
    "\"\"\").strip()\n",
    "\n",
    "schema = {                                 # strict JSON schema = no postâ€‘cleanup\n",
    "    \"name\": \"webscreen_classification\",\n",
    "    \"strict\": True,\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"landing_page\": {\"type\": \"boolean\"},\n",
    "            \"aesthetic\":    {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 5}\n",
    "        },\n",
    "        \"required\": [\"landing_page\", \"aesthetic\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "lines = []\n",
    "for row in ds:\n",
    "    data_uri = to_data_uri(row[\"image\"])\n",
    "    \n",
    "    body = {\n",
    "        \"model\": VISION_MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}},\n",
    "                {\"type\": \"text\",      \"text\": \"Classify this screenshot.\"}\n",
    "            ]}\n",
    "        ],\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": schema\n",
    "        },\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    \n",
    "    lines.append(json.dumps({\n",
    "        \"custom_id\": f\"img_{row['image_id']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": body\n",
    "    }))\n",
    "\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: soY_tB5HRg1_pB38I15xw\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "jsonl_blob = \"\\n\".join(lines).encode(\"utf-8\")\n",
    "\n",
    "buf = BytesIO(jsonl_blob)\n",
    "buf.name = \"batch_input.jsonl\"          # ğŸ‘ˆ give it a legit filename\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "    file=buf,\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(\"Uploaded:\", batch_input_file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: vI7MCxo-MkOf7JHghau-S Status: in_progress\n"
     ]
    }
   ],
   "source": [
    "batch = client.batches.create(\n",
    "    input_file_id=batch_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    ")\n",
    "print(\"Batch ID:\", batch.id, \"Status:\", batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: in_progress\n",
      "Batch status: completed\n",
      "Final batch object:\n",
      "Batch(id='vI7MCxo-MkOf7JHghau-S', completion_window='24h', created_at=1752183978369, endpoint='/v1/chat/completions', input_file_id='soY_tB5HRg1_pB38I15xw', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1752184091529, error_file_id='37qbmw0ZBCLbOQaTezI3u', errors=None, expired_at=None, expires_at=1752270378368, failed_at=None, finalizing_at=None, in_progress_at=1752183978421, metadata=None, output_file_id='UkkudiDWtuIzJdbUvG7X1', request_counts=BatchRequestCounts(completed=0, failed=200, total=200))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Poll for batch status until it's no longer \"in_progress\"\n",
    "while True:\n",
    "    batch = client.batches.retrieve(batch.id)\n",
    "    print(\"Batch status:\", batch.status)\n",
    "    if batch.status != \"in_progress\":\n",
    "        break\n",
    "    time.sleep(10)  # Wait 10 seconds before polling again\n",
    "\n",
    "print(\"Final batch object:\")\n",
    "print(batch)\n",
    "\n",
    "output_file = client.files.content(batch.output_file_id)\n",
    "print(output_file.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# show results\n",
    "print(output_file.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
